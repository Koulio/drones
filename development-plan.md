The objective is to create several stages of product that increase in useful capability over time 
(rather than individual components that can't do much unless assembled together at the end):

A. Mobile phone controlling Phantom 3 drone:

   0. GPS coordinates input (in a local file to start, max altitude for failsafe)
   0. Calculate Flight path (for shortest mission time) given GPS.
   0. Take-off command (from interactive display in the F150
   0. RTH (Return to home)
   0. Abort mission for manual piloting.

   0. Chromecast or iOS AirPlay Mirroring for App broadcast
   0. Stream video to cloud web server for the international press to watch ;)
   0. Streaming live footage to the F150 (800 pixels wide by 384 pixels every 4 seconds)

B. Image recognition and route planning/prioritization:

   0. Avoid obstacles (wind, go around )
   0. Assimilate recordings (does it look like a survivor tag).
   0. Recognize GPS coordinates
   0. Abort landing.

C. Mobile phone controlling M100 drone (second round):

D. Mobile phone controlling M100 drone (second round):

   0. Return to home (RTH) around known objects.
   0. Landing on ground
   0. Landing on a moving vehicle

Along the way:

0. Calibration (barometer for altitude)
